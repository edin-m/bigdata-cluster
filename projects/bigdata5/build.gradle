plugins {
    id 'java'
    id 'scala'
    id 'com.github.johnrengelman.shadow' version '5.1.0'
}

group 'io.leres'
version '1.0-SNAPSHOT'

sourceCompatibility = 1.8

repositories {
    mavenCentral()
}

import com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar

import java.util.stream.Collectors

task buildOnlyDependencies(type: ShadowJar) {
    archiveFileName = project.name + '-deps.jar'
    zip64 true
    configurations = [project.configurations.runtime]
}

task buildOnlyDependencies2(type: Jar) {
    archiveFileName = project.name + '-deps.jar'
    zip64 true
    from {
//        configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } +
        configurations.testCompile.collect { it.isDirectory() ? it : zipTree(it) }

    }
}

task fatJar(type: Jar) {
    manifest {
        attributes 'Implementation-Title': 'Gradle Jar File Example',
                'Implementation-Version': version,
                'Main-Class': 'io.leres.bigdata5.Main'
    }
    baseName = project.name + '-all'
    from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }
    zip64 true
    with jar
}

task allDeps(type: Jar) {
    baseName = project.name + '-deps'
    from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }
    zip64 true
    with jar
}

dependencies {
    testCompile group: 'junit', name: 'junit', version: '4.12'

    // hadoop
    compile group: 'org.apache.hadoop', name: 'hadoop-common', version: '3.2.0'
    compile group: 'org.apache.hadoop', name: 'hadoop-hdfs', version: '3.2.0'
    compile group: 'org.apache.hadoop', name: 'hadoop-mapreduce-client-core', version: '3.2.0'
    compile group: 'org.apache.hadoop', name: 'hadoop-client', version: '3.2.0'
    compile group: 'org.apache.hadoop', name: 'hadoop-aws', version: '3.2.0'

    testCompile group: 'org.apache.hadoop', name: 'hadoop-minicluster', version: '3.2.0'

    // scala -- match the scala version with spark version
    implementation 'org.scala-lang:scala-library:2.11.12'
    testImplementation group: 'org.scalatest', name: 'scalatest_2.13', version: '3.0.8'

    // kafka
    compile group: 'org.apache.kafka', name: 'kafka_2.12', version: '2.3.0'
    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.3.0'
    compile group: 'org.apache.kafka', name: 'kafka-streams', version: '2.3.0'

    // spark
    compile group: 'org.apache.spark', name: 'spark-core_2.12', version: '2.4.3'
    compile group: 'org.apache.spark', name: 'spark-sql_2.12', version: '2.4.3'
    compile group: 'org.apache.spark', name: 'spark-streaming_2.12', version: '2.4.3'
    // spark-kafka
    compile group: 'org.apache.spark', name: 'spark-streaming-kafka-0-10_2.12', version: '2.4.3'

}

task copyRuntimeLibs(type: Copy) {
    into "$buildDir/output/deps"
    from configurations.testRuntime + configurations.runtime
}

def HADOOP_HOME = "/bigdata/downloads/hadoop-3.2.0"
def HDFS_APP_URL = "hdfs://nodemaster:9000/app"

task deployDependenciesPre(type: Exec) {
    commandLine "$HADOOP_HOME/bin/hdfs", "dfs", "-mkdir", "-p", "$HDFS_APP_URL/${project.name}"
}

task writeDepsToFile {
    def files = fileTree("$buildDir/output/deps").filter { it.isFile() }.files.name
    def str = files.collect { "$HDFS_APP_URL/deps/" + it }.join(",")

    new File("deps.txt").text = str
}

// run from inside vagrant
task deployDependencies(type: Exec) {
    dependsOn copyRuntimeLibs, deployDependenciesPre, writeDepsToFile
    commandLine "$HADOOP_HOME/bin/hdfs", "dfs", "-copyFromLocal", "-f", "$buildDir/output/deps", "$HDFS_APP_URL/${project.name}"
}

/**
 jar {zip64 true
 archiveName = "StackOverFlowSurvey-spark.jar"
 from {configurations.compile.collect {it.isDirectory() ? it : zipTree(it)}}manifest {attributes 'Main-Class': 'com.sparkTutorial.sparkSql.StackOverFlowSurvey'}exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA'}*/
